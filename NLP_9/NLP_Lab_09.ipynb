{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW_tb3w89onR"
      },
      "source": [
        "#**LAB ASSINGMENT 9 - NLP**\n",
        "Harshvardhan Aditya \n",
        "E20CSE365"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVp9II-B0wbp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SqiwZep1XRn",
        "outputId": "c790da1f-dc04-4f33-ccfe-0f549a92210a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus length: 314\n"
          ]
        }
      ],
      "source": [
        "text = open('/content/dataset_hindi_para.txt').read().lower()\n",
        "print('Corpus Length:', len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiouI4c_2YwU"
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words = tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aU5tEnu92gXp"
      },
      "outputs": [],
      "source": [
        "unique_words = np.unique(words)\n",
        "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZVBkyUH2kgZ",
        "outputId": "0e597c1d-f379-479b-8a0c-05fdb8dd4e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['यह', 'आप', 'व', 'भ', 'न', 'न', 'व', 'षय', 'पर', 'ह', 'द', 'न', 'ब', 'ध', 'पढ़', 'और', 'स', 'ख', 'सकत', 'ह', 'ज', 'स', 'क', 'ल', 'और', 'क', 'ल', 'ज', 'व', 'द', 'य', 'र', 'थ', 'य', 'क', 'प', 'छ', 'ज', 'त', 'ह', 'यह', 'आप', 'व', 'भ', 'न', 'न', 'व', 'षय', 'पर', 'ह', 'द', 'न', 'ब', 'ध', 'न', 'ब', 'ध', 'ल', 'खन', 'ह', 'ज', 'सभ', 'छ', 'त', 'र', 'एव', 'आम', 'न', 'गर', 'क', 'क', 'ल', 'ए', 'उपय', 'ग', 'ह', 'इस', 'व', 'बस', 'इट', 'पर', 'म', 'न', 'व', 'यवस', 'थ', 'त', 'र', 'प', 'स', 'सभ', 'प', 'रक', 'र', 'क', 'न', 'ब', 'ध', 'क', 'स']\n",
            "ग\n"
          ]
        }
      ],
      "source": [
        "WORD_LENGTH = 100\n",
        "prev_words = []\n",
        "next_words = []\n",
        "for i in range(len(words) - WORD_LENGTH):\n",
        "    prev_words.append(words[i:i + WORD_LENGTH])\n",
        "    next_words.append(words[i + WORD_LENGTH])\n",
        "print(prev_words[0])\n",
        "print(next_words[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMk3UCwL2oyN"
      },
      "outputs": [],
      "source": [
        "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
        "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr-z7Abj3K--"
      },
      "outputs": [],
      "source": [
        "for i, each_words in enumerate(prev_words):\n",
        "    for j, each_word in enumerate(each_words):\n",
        "        X[i, j, unique_word_index[each_word]] = 1\n",
        "    Y[i, unique_word_index[next_words[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72LugWSw3N3J",
        "outputId": "148e6c18-1d70-41e7-ee4c-2a373f4474de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False  True False False False False\n",
            " False False False False False False False]\n"
          ]
        }
      ],
      "source": [
        "print(X[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLR_UXNL3RWh"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pDzDvsM3WB1",
        "outputId": "083186f0-905f-479e-d48c-cea1864bd2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.7523 - accuracy: 0.1250 - val_loss: 5.0777 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 3.1016 - accuracy: 0.1250 - val_loss: 3.9013 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 3.5698 - accuracy: 0.1875 - val_loss: 6.2244 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 3.1641 - accuracy: 0.0625 - val_loss: 6.3079 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 3.1912 - accuracy: 0.1875 - val_loss: 5.7160 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.7959 - accuracy: 0.0625 - val_loss: 6.7646 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.6276 - accuracy: 0.2500 - val_loss: 6.7064 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.5915 - accuracy: 0.1875 - val_loss: 6.9743 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.5236 - accuracy: 0.1875 - val_loss: 6.4443 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.4569 - accuracy: 0.1250 - val_loss: 7.2105 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3229 - accuracy: 0.5000 - val_loss: 6.6378 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.1553 - accuracy: 0.6250 - val_loss: 7.0684 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.1431 - accuracy: 0.1250 - val_loss: 6.7347 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.0811 - accuracy: 0.3750 - val_loss: 5.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 1.9805 - accuracy: 0.3125 - val_loss: 3.2384 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 4.5105 - accuracy: 0.0000e+00 - val_loss: 5.2254 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 2.8357 - accuracy: 0.1875 - val_loss: 6.2226 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 2.6396 - accuracy: 0.0625 - val_loss: 5.4493 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 3.2784 - accuracy: 0.3125 - val_loss: 3.7688 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 2.7534 - accuracy: 0.1875 - val_loss: 7.2804 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1FrALMK3kBU"
      },
      "outputs": [],
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
        "    for t, word in enumerate(text.split()):\n",
        "        print(word)\n",
        "        x[0, t, unique_word_index[word]] = 1\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGHlbjFR4Z7v"
      },
      "outputs": [],
      "source": [
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SAiSdk04f_S"
      },
      "outputs": [],
      "source": [
        "def predict_completions(text, n=3):\n",
        "    if text == \"\":\n",
        "        return(\"0\")\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [unique_words[idx] for idx in next_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10GpMNKo4iRJ",
        "outputId": "8c2da537-49ba-47de-a403-73e072553c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "correct sentence:  यहाँ आप विभिन्न विषयों पर हिंदी\n",
            "Sequence:  यह आप व भ न\n",
            "यह\n",
            "आप\n",
            "व\n",
            "भ\n",
            "न\n",
            "next possible words:  ['ह', 'य', 'द', 'यह', 'त']\n"
          ]
        }
      ],
      "source": [
        "q =  \"यहाँ आप विभिन्न विषयों पर हिंदी\"\n",
        "print(\"Correct sentence: \",q)\n",
        "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"The Sequence: \",seq)\n",
        "print(\"The next possible words: \", predict_completions(seq, 5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}